# Sistema de Detecci√≥n de Fraude M√©dico

Un sistema completo de detecci√≥n de fraude m√©dico que combina machine learning con interpretabilidad avanzada (SHAP y LIME) y un asistente de IA especializado.

## Caracter√≠sticas Principales

### ü§ñ AI Assistant Inteligente
- **Contexto Enriquecido**: El AI Assistant tiene acceso completo a:
  - Datos del proveedor (reembolsos, reclamos, beneficiarios, etc.)
  - Resultados de predicci√≥n (probabilidad de fraude, nivel de riesgo)
  - Explicaciones SHAP (contribuci√≥n exacta de cada feature)
  - Explicaciones LIME (interpretaci√≥n local del modelo)
  - M√©tricas del dashboard (condiciones cr√≥nicas, distribuci√≥n de g√©nero)
  - Comparaci√≥n entre m√©todos de interpretabilidad

- **Preguntas Sugeridas Adaptativas**: 
  - Se adaptan seg√∫n el resultado de la predicci√≥n (fraude/no fraude)
  - Incluyen preguntas espec√≠ficas sobre SHAP, LIME y condiciones cr√≥nicas
  - Proporcionan insights relevantes al contexto del proveedor

- **An√°lisis Multiling√ºe**: 
  - Detecta autom√°ticamente el idioma dominante de la conversaci√≥n
  - Responde siempre en el idioma principal del usuario
  - Soporte para espa√±ol, ingl√©s y portugu√©s

### üìä Interpretabilidad Avanzada
- **SHAP (SHapley Additive exPlanations)**: Explicaciones precisas de la contribuci√≥n de cada feature
- **LIME (Local Interpretable Model-agnostic Explanations)**: Interpretaci√≥n local para predicciones espec√≠ficas
- **Comparaci√≥n de M√©todos**: An√°lisis de acuerdo entre SHAP y LIME
- **Visualizaciones Interactivas**: Gr√°ficos de contribuci√≥n de features con impacto positivo/negativo

### üè• An√°lisis de Proveedores
- **Dashboard Completo**: M√©tricas clave, condiciones cr√≥nicas, distribuci√≥n demogr√°fica
- **Predicciones Individuales**: An√°lisis detallado por proveedor
- **An√°lisis Masivo**: Procesamiento de m√∫ltiples proveedores
- **M√©tricas de Rendimiento**: ROC-AUC, precisi√≥n, recall, F1-score

## üèóÔ∏è Arquitectura del Sistema

```
proyecto-ia/
‚îú‚îÄ‚îÄ backend/                 # Servidor FastAPI con modelo ML
‚îÇ   ‚îú‚îÄ‚îÄ agents/             # Agentes de procesamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestor.py     # Procesamiento de datos CSV
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predictor.py    # Predicciones con modelo XGBoost
‚îÇ   ‚îú‚îÄ‚îÄ data/               # Datos y archivos procesados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_uploaded/  # Archivos CSV subidos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_final/     # test_final.csv generado
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Modelo entrenado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ xgb_fraud_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ metrics/            # M√©tricas del modelo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ xgb_fraud_metrics.json
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Servidor FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt    # Dependencias Python
‚îî‚îÄ‚îÄ frontend/               # Aplicaci√≥n React
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ components/     # Componentes React
    ‚îÇ   ‚îú‚îÄ‚îÄ services/       # Servicios de API
    ‚îÇ   ‚îî‚îÄ‚îÄ App.tsx         # Aplicaci√≥n principal
    ‚îî‚îÄ‚îÄ public/
        ‚îî‚îÄ‚îÄ data/           # Datos de muestra
```

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- Python 3.8+
- Node.js 16+
- npm o yarn

### Backend (Python/FastAPI)

1. **Navegar al directorio backend:**
   ```bash
   cd backend
   ```

2. **Crear entorno virtual:**
   ```bash
   python -m venv venv
   ```

3. **Activar entorno virtual:**
   ```bash
   # Windows
   venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
   ```

4. **Instalar dependencias:**
   ```bash
   pip install -r requirements.txt
   ```

5. **Ejecutar el servidor:**
   ```bash
   python main.py
   ```

El servidor estar√° disponible en `http://localhost:8000`

### Frontend (React)

1. **Navegar al directorio frontend:**
   ```bash
   cd frontend
   ```

2. **Instalar dependencias:**
   ```bash
   npm install
   ```

3. **Ejecutar en modo desarrollo:**
   ```bash
   npm run dev
   ```

La aplicaci√≥n estar√° disponible en `http://localhost:5173`

> **Nota:** El frontend est√° configurado para redirigir autom√°ticamente las rutas `/api` al backend durante el desarrollo (ver `vite.config.ts`).

## üìä Caracter√≠sticas del Sistema

### Backend API (Principales endpoints)

- **POST `/upload`** ‚Äî Subir archivos CSV de test
- **POST `/ingest`** ‚Äî Procesar y consolidar los archivos subidos, generar `test_final.csv`
- **POST `/predict`** ‚Äî Realizar predicciones de fraude sobre los datos procesados
- **GET `/metricas`** ‚Äî Obtener m√©tricas del modelo ML
- **GET `/health`** ‚Äî Verificar estado del sistema y modelo
- **GET `/api/test-final-preview`** ‚Äî Obtener las primeras 10 filas de `test_final.csv` para previsualizaci√≥n en el frontend

### Frontend

- **P√°gina de Inicio** ‚Äî Descripci√≥n del sistema
- **Bulk Input** ‚Äî Subida masiva de archivos CSV, procesamiento, preview y predicci√≥n
- **Model Overview** ‚Äî M√©tricas y rendimiento del modelo
- **Single Prediction** ‚Äî Predicciones individuales

### Modelo ML

- **Algoritmo:** XGBoost
- **Features:** Total_Reimbursed, Mean_Reimbursed, Claim_Count, Unique_Beneficiaries, Pct_Male
- **M√©tricas:** ROC-AUC: 94.64%, Precision: 54.86%, Recall: 75.59%

## üìÅ Formato de Datos

### CSV de Entrada Requerido

```csv
Provider,TotalClaims,NumInpatientClaims,NumOutpatientClaims,TotalAmountReimbursed,MeanAmountReimbursed,AvgClaimDurationDays,NumUniqueDiagnosisCodes,NumUniqueProcedureCodes,NumUniqueBeneficiaries
PROVIDER001,1250,45,1205,4500000,3600,12.5,85,120,980
```

### CSV de Salida

```csv
Provider,Prediccion,Probabilidad_Fraude
PROVIDER001,0,0.2345
PROVIDER002,1,0.7890
```

## üß™ Pruebas

### Probar la API

```bash
cd backend
python test_api.py
```

### Probar el Frontend

1. Abrir `http://localhost:5173`
2. Ir a "Bulk Input"
3. Cargar datos de muestra
4. Ejecutar predicciones

## üîß Uso del Sistema

### 1. Subir Datos

1. Navegar a "Bulk Input" en el frontend
2. Arrastrar y soltar archivos CSV o hacer clic en "Choose File"
3. Verificar que los archivos tengan los nombres y columnas requeridas
4. Los archivos se subir√°n autom√°ticamente al backend

### 2. Procesar Datos

1. Hacer clic en **Process Data**
2. El sistema procesar√° los datos y generar√° las features
3. (Opcional) Hacer clic en **Toggle Preview** para ver las primeras filas del dataset consolidado

### 3. Predecir

1. Hacer clic en **Predict**
2. El sistema ejecutar√° las predicciones sobre los datos procesados

### 4. Ver Resultados

1. Los resultados se mostrar√°n en una tabla
2. Cada provider tendr√°:
   - Predicci√≥n (Fraude/No Fraude)
   - Probabilidad de fraude
3. Descargar resultados en CSV

### 5. Ver M√©tricas del Modelo

1. Navegar a "Model Overview"
2. Ver m√©tricas de rendimiento
3. Analizar importancia de features

## üìà M√©tricas del Modelo

- **ROC-AUC:** 0.9464 (94.64%)
- **Precision:** 0.5486 (54.86%)
- **Recall:** 0.7559 (75.59%)
- **F1-Score:** 0.6358 (63.58%)

## üîç Troubleshooting

### Problemas Comunes

1. **Error de CORS**
   - Verificar que el backend est√© corriendo en puerto 8000
   - Verificar configuraci√≥n CORS en `main.py`

2. **Error de Modelo**
   - Verificar que `xgb_fraud_model.pkl` existe en `models/`
   - Verificar que las dependencias est√©n instaladas

3. **Error de Datos**
   - Verificar formato y nombres de archivos CSV
   - Verificar columnas requeridas
   - Verificar tipos de datos

### Logs

Los logs se muestran en la consola del backend.

## üìù Notas T√©cnicas

- El modelo XGBoost fue entrenado con datos de reclamaciones m√©dicas
- Las features se calculan autom√°ticamente desde los datos brutos
- El sistema maneja errores de forma robusta
- La interfaz es responsive y moderna
- El c√≥digo est√° bien documentado y modular

## ü§ù Contribuci√≥n

1. Fork el proyecto
2. Crear rama de feature (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver `LICENSE` para m√°s detalles. 